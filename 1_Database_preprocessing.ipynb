{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Algorithms as alg\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "import os\n",
    "\n",
    "os.makedirs('dataframes', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'database\\RECORDS'\n",
    "\n",
    "with open(path, 'r') as file:\n",
    "    tapes = [int(line.strip()) for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['+', 'N', 'A', 'V', '~', '|', 'Q', '/', 'f', 'x', 'F', 'j', 'L', 'a', 'J', 'R', '[', '!', ']', 'E', 'S', '\"', 'e']\n"
     ]
    }
   ],
   "source": [
    "number_of_symbols = {}\n",
    "\n",
    "for tape in tapes:\n",
    "    filename = 'database/'+ str(tape)\n",
    "    record = wfdb.rdrecord(filename)\n",
    "\n",
    "    ann= wfdb.rdann(filename, 'atr')\n",
    "\n",
    "    for symbol in ann.symbol:\n",
    "        if symbol in number_of_symbols:\n",
    "            number_of_symbols[symbol] += 1\n",
    "        else:\n",
    "            number_of_symbols[symbol] = 1\n",
    "        \n",
    "\n",
    "unique_symbols = list(number_of_symbols.keys())\n",
    "\n",
    "print(unique_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of each symbol: \n",
      "  -> {'+': 1291, 'N': 75052, 'A': 2546, 'V': 7130, '~': 616, '|': 132, 'Q': 33, '/': 7028, 'f': 982, 'x': 193, 'F': 803, 'j': 229, 'L': 8075, 'a': 150, 'J': 83, 'R': 7259, '[': 6, '!': 472, ']': 6, 'E': 106, 'S': 2, '\"': 437, 'e': 16}\n",
      "All unique symbols: \n",
      "  -> ['+', 'N', 'A', 'V', '~', '|', 'Q', '/', 'f', 'x', 'F', 'j', 'L', 'a', 'J', 'R', '[', '!', ']', 'E', 'S', '\"', 'e']\n",
      "Number of all symbols:  112647\n",
      "Target symbols: \n",
      "  -> ['N', 'L', 'R', 'A', 'V', '/']\n",
      "Number of all target symbols:  107090\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of each symbol: \\n  ->\", number_of_symbols)\n",
    "print(\"All unique symbols: \\n  ->\", unique_symbols)\n",
    "\n",
    "number_of_all_symbols = 0\n",
    "for s in unique_symbols:\n",
    "    number_of_all_symbols += number_of_symbols[s]\n",
    "\n",
    "print(\"Number of all symbols: \", number_of_all_symbols)\n",
    "\n",
    "target_symbols = ['N', 'L', 'R', 'A', 'V', '/'] \n",
    "\n",
    "number_of_target_symbols = 0\n",
    "for s in target_symbols:\n",
    "    number_of_target_symbols += number_of_symbols[s]\n",
    "\n",
    "print(\"Target symbols: \\n  ->\", target_symbols)\n",
    "print(\"Number of all target symbols: \", number_of_target_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe saved as dataframes\\df_mitdb.pkl\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(index=tapes, columns=['ECG', 'True_peak', 'Peak_type'])\n",
    "\n",
    "for index in df.index:\n",
    "    filename = 'database/'+ str(index)\n",
    "    record = wfdb.rdrecord(filename)\n",
    "\n",
    "    ecg = list(map(lambda x: x[0], record.p_signal))\n",
    "    ann= wfdb.rdann(filename, 'atr')\n",
    "    # annotations is a list of tuples locations and annotation letter [(77, 'N'), (370, 'N'), (662, 'N'), ...]\n",
    "    annotations = list(filter(lambda x: x[1] in unique_symbols, zip(ann.sample, ann.symbol)))\n",
    "    x2, a2 = zip(*annotations)\n",
    "\n",
    "    df.at[index, 'ECG'] = ecg\n",
    "    df.at[index, 'True_peak'] = np.array(x2)  \n",
    "    df.at[index, 'Peak_type'] = np.array(a2)  \n",
    "\n",
    "name = 'dataframes\\df_mitdb.pkl'\n",
    "df.to_pickle(name)\n",
    "print(f\"Dataframe saved as {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe saved as dataframes\\df_all_algorithms.pkl\n"
     ]
    }
   ],
   "source": [
    "df_algorithms = pd.DataFrame(index=tapes, columns=['Alg1', 'Alg2', 'Alg3', 'Alg4', 'Alg5'])\n",
    "\n",
    "for index in df_algorithms.index:\n",
    "    filename = 'database/'+ str(index)\n",
    "    record = wfdb.rdrecord(filename)\n",
    "\n",
    "    ecg = list(map(lambda x: x[0], record.p_signal))\n",
    "\n",
    "    df_algorithms.at[index, 'Alg1'] = np.array(alg.alg1_spanish(ecg))\n",
    "    df_algorithms.at[index, 'Alg2'] = np.array(alg.alg4_polish_20210222(ecg))\n",
    "    df_algorithms.at[index, 'Alg3'] = np.array(alg.alg3_iranian(ecg))\n",
    "    df_algorithms.at[index, 'Alg4'] = np.array(alg.alg5_pan_tompkins(ecg))\n",
    "    df_algorithms.at[index, 'Alg5'] = np.array(alg.Alg5_Turkish(ecg))\n",
    "\n",
    "\n",
    "name = 'dataframes\\df_all_algorithms.pkl'\n",
    "df_algorithms.to_pickle(name)\n",
    "print(f\"Dataframe saved as {name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
